{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0LOaPyAgCU8"
      },
      "source": [
        "#  RDDs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxqIrsY-gCVB"
      },
      "source": [
        "# Creamos un contexto para crear RDDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3SkkrkIgCVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772a225c-4f9c-4e43-f1c6-d3d0e8eb1a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark --quiet\n",
        "from pyspark import SparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X-TkHs-gCVE"
      },
      "outputs": [],
      "source": [
        "sc = SparkContext(master = \"local\", appName=\"TransformacionesyAcciones\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYNeSv5EgCVF"
      },
      "source": [
        "# Un RDD es una colección inmutable y distribuida de elementos\n",
        "\n",
        "### Spark automaticamente distribuye los datos y paraleliza las operaciones\n",
        "\n",
        "### Los RDD realmente cargan colecciones de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yfNRIqPgCVF"
      },
      "outputs": [],
      "source": [
        "rdd1 = sc.parallelize([1,2,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7daw3WsugCVF"
      },
      "source": [
        "### Debido a la propiedad de distribución que tienen los RDD, en su creación, podemos particionar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV_9CtH-gCVG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rdd2 = sc.parallelize(np.array(range(100)),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXf9xyz4gCVG"
      },
      "source": [
        "### Verificamos el tipo de dato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6IXNzw2gCVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d73984f-7ed8-4396-c732-99c4b813fdcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "type(rdd1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9fdoJ87gCVG"
      },
      "source": [
        "### Vemos el contenido\n",
        "\n",
        "Veremos distintas tecnicas apropiadas para ver el contenido de los RDDs y Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzqUUjhCgCVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2fec76a-3e87-4d3f-edc2-3779f51b3312"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "rdd1.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvXwqRwdgCVH"
      },
      "source": [
        "# Carga de un arhivo CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfQ67xw1gCVI"
      },
      "source": [
        "### Cargamos un RDDs\n",
        "\n",
        "El método textFile busca el archivo en la ruta indicada\n",
        "\n",
        "Cambia el valor de la ruta para que apunte a la ruta donde tienes los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AG-1zOcgCVI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "equiposOlimpicosRDD = sc.textFile(\"/content/drive/MyDrive/Colab Notebooks/RED.ES/Datos Ejercicios/M6/paises.csv\",2).map(lambda line : line.split(\",\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGKXqN4sgCVI"
      },
      "source": [
        "### Vemos el contenido\n",
        "\n",
        "El método take es otro método existnte para poder visualizar el contenido de los RDDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA3o7cq1gCVI"
      },
      "outputs": [],
      "source": [
        "equiposOlimpicosRDD.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfOUKBkvgCVJ"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Libreria Spark\n",
        "!pip install pyspark --quiet\n",
        "from pyspark import SparkContext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXp9Ah75Vhdw",
        "outputId": "a3d006c0-acb4-4032-ce54-655c441e2e0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir contexto\n",
        "sc = SparkContext(master = \"local\", appName=\"TransformacionesyAcciones\")"
      ],
      "metadata": {
        "id": "R3W-OF19WH7w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.\tCrea una lista de Python y guárdalo en una variable que se llame lista_ejercicio\n",
        "lista_ejercicio = [2,4,6,8,10]"
      ],
      "metadata": {
        "id": "WSboNUjUJUCO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.\tAplica un map() a la lista con una lambda que multiplique por tres a cada elemento.\n",
        "list(map(lambda x: x*3, lista_ejercicio))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Tmim9MLVe_",
        "outputId": "4e830a70-e8e1-4deb-eb63-92851a0ccace"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 12, 18, 24, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9.\tAhora paraleliza la lista lista_ejercicio y guárdalo en la variable rdd_ejercicio.\n",
        "rdd_ejercicio = sc.parallelize(lista_ejercicio)\n"
      ],
      "metadata": {
        "id": "WsiX3xqPJkI3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.\tAplica un map() al RDD rdd_ejercicio que multiplique por tres a cada elemento. Fijate en las diferencias de sintaxis. El ejercicio 1 y 2 son secuenciales y el 3 y 4 paralelizados.\n",
        "rdd_transformado = rdd_ejercicio.map(lambda x:x*3)\n"
      ],
      "metadata": {
        "id": "7G70OxXpJoXK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11.\tAhora desparaleliza el RDD rdd_ejercicio.\n",
        "rdd_transformado.collect()\n",
        "sc.stop()\n"
      ],
      "metadata": {
        "id": "ZU095lHAJs6e"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}